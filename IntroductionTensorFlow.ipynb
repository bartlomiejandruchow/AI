{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpjS4aCuyNCERc8qUsrb89",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bartlomiejandruchow/AI/blob/main/IntroductionTensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ih1d2nOy7db"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_samples_per_class = 1000\n",
        "positive_samples = np.random.multivariate_normal(mean=[0, 3], cov=[[1, 0.5], [0.5, 1]], size=num_samples_per_class)\n",
        "negative_samples = np.random.multivariate_normal(mean=[3, 0], cov=[[1, 0.5], [0.5, 1]], size=num_samples_per_class)\n",
        "\n",
        "inputs = np.vstack((positive_samples, negative_samples)).astype(np.float32)\n",
        "\n",
        "targets = np.vstack((np.zeros((num_samples_per_class, 1),dtype=\"float32\"),np.ones((num_samples_per_class, 1),dtype=\"float32\")))\n",
        "\n",
        "\n",
        "input_dim = 2\n",
        "output_dim = 1\n",
        "\n",
        "W = tf.Variable(initial_value = tf.random.uniform(shape=(input_dim, output_dim)))\n",
        "b = tf.Variable(initial_value = tf.zeros(shape = (output_dim)))\n",
        "\n",
        "def model(inputs, W, b):\n",
        "  return tf.matmul(inputs, W) + b\n",
        "\n",
        "def mean_squared_error(targets, predictions):\n",
        "  per_sample_losses = tf.square(targets - predictions)\n",
        "  return tf.reduce_mean(per_sample_losses)\n",
        "\n",
        "learning_rate = 0.1\n",
        "\n",
        "def training_step(inputs, targets, W, b):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inputs, W, b)\n",
        "    loss = mean_squared_error(targets, predictions)\n",
        "  grad_loss_wrt_W, grad_loss_wrt_b = tape.gradient(loss, [W, b])\n",
        "  W.assign_sub(grad_loss_wrt_W * learning_rate)\n",
        "  b.assign_sub(grad_loss_wrt_b * learning_rate)\n",
        "  return loss\n",
        "\n",
        "for step in range(100):\n",
        "  loss = training_step(inputs, targets, W, b)\n",
        "  print(f'Loss at step {step} : {loss:.4f}')\n",
        "\n",
        "x = np.linspace(-1, 4, 100)\n",
        "y = -W[0]/W[1]*x + (0.5 - b)/W[1]\n",
        "plt.plot(x, y, '-r')\n",
        "plt.scatter(inputs[:,0], inputs[:,1], c = targets[:,0])\n",
        "#plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PyToarch\n",
        "\n"
      ],
      "metadata": {
        "id": "b7eUzPooRRXF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}